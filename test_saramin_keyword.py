import requests
from bs4 import BeautifulSoup
import json
from urllib.parse import quote

# Saramin ì§ì ‘ í…ŒìŠ¤íŠ¸
keywords = [
    "ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸",
    "ë°ì´í„° ì—”ì§€ë‹ˆì–´",
    "ë¨¸ì‹ ëŸ¬ë‹",
    "ì¸ê³µì§€ëŠ¥",
    "ë°ì´í„°",
]

for keyword in keywords:
    print(f"\n{'='*60}")
    print(f"ğŸ” ê²€ìƒ‰: {keyword}")
    print(f"{'='*60}")
    
    # URL ì¸ì½”ë”©
    encoded_kw = quote(keyword)
    url = f"https://www.saramin.co.kr/zf_user/search?searchword={encoded_kw}"
    print(f"URL: {url[:80]}...")
    
    try:
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
        r = requests.get(url, headers=headers, timeout=10)
        
        if r.status_code != 200:
            print(f"âŒ ìƒíƒœ ì½”ë“œ: {r.status_code}")
            continue
        
        soup = BeautifulSoup(r.text, "html.parser")
        
        # ê³µê³  í•­ëª© ì°¾ê¸°
        items = soup.select("div.item_recruit")
        print(f"âœ… ì°¾ì€ ê³µê³  ìˆ˜: {len(items)}")
        
        if items:
            # ì²« 3ê°œ í•­ëª©ì˜ ì œëª© ì¶œë ¥
            for i, item in enumerate(items[:3]):
                title_tag = item.select_one("h2.job_tit a")
                if title_tag:
                    title = title_tag.text.strip()
                    print(f"  {i+1}. {title[:60]}")
    
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
